{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQvIcgSdtWkc",
        "colab_type": "code",
        "outputId": "e965aa54-ebd4-46e5-dd60-332a2550063a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.34)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.83)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.224)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.8.19)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.6.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.224 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.224)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZXyoGcthuO",
        "colab_type": "code",
        "outputId": "3b10e19b-683f-44d8-a2e0-83d97183fee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from pytorch_transformers import (WEIGHTS_NAME, AdamW, WarmupLinearSchedule,\n",
        "                                  BertConfig, BertForMaskedLM, BertTokenizer)\n",
        "\n",
        "import random\n",
        "manualSeed = 999\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForMaskedLM, BertTokenizer)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUnwR7l85Q4-",
        "colab_type": "code",
        "outputId": "5d58340d-6177-4cbb-fdb0-dfbea021157e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from urllib import request\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from typing import *\n",
        "\n",
        "save_dir = '/content/corpus/'\n",
        "file_list: List[str] = ['condensed_2009.json.zip', 'condensed_2010.json.zip', 'condensed_2011.json.zip', 'condensed_2012.json.zip', 'condensed_2013.json.zip', 'condensed_2014.json.zip', 'condensed_2015.json.zip', 'condensed_2016.json.zip', 'condensed_2017.json.zip', 'condensed_2018.json.zip']\n",
        "url_root = 'https://github.com/bpb27/trump_tweet_data_archive/raw/master/'\n",
        "\n",
        "# Download Trump tweets\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "for file_name in file_list:\n",
        "  print(f'Downloading {file_name}..')\n",
        "  file_path = save_dir + file_name\n",
        "  request.urlretrieve(url_root + file_name, file_path)\n",
        "  with ZipFile(file_path, 'r') as zip:\n",
        "    zip.extractall(save_dir)\n",
        "  os.remove(file_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading condensed_2009.json.zip..\n",
            "Downloading condensed_2010.json.zip..\n",
            "Downloading condensed_2011.json.zip..\n",
            "Downloading condensed_2012.json.zip..\n",
            "Downloading condensed_2013.json.zip..\n",
            "Downloading condensed_2014.json.zip..\n",
            "Downloading condensed_2015.json.zip..\n",
            "Downloading condensed_2016.json.zip..\n",
            "Downloading condensed_2017.json.zip..\n",
            "Downloading condensed_2018.json.zip..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peVKTab-5YF1",
        "colab_type": "code",
        "outputId": "20c9319f-2862-4258-9468-4122ffa9a703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import json\n",
        "\n",
        "MAX_TWEET_LENGTH = 150\n",
        "tweets = []\n",
        "\n",
        "file_list = list(map(lambda s: s.replace('.zip', ''), file_list))\n",
        "for f in file_list:\n",
        "  with open(save_dir + f, 'r', encoding='utf-8') as fp:\n",
        "    raw_tweets = json.load(fp)\n",
        "    for raw_tweet in raw_tweets:\n",
        "      text = raw_tweet[\"text\"]\n",
        "      if len(text) < (MAX_TWEET_LENGTH - 2): # -2 for begin and end tokens\n",
        "        tweets.append(text)\n",
        "\n",
        "print(str(len(tweets)) + \" tweets\")\n",
        "for tweet in tweets[:5]:\n",
        "  print(tweet)\n",
        "print(\"...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33721 tweets\n",
            "From Donald Trump: Wishing everyone a wonderful holiday & a happy, healthy, prosperous New Year. Let’s think like champions in 2010!\n",
            "Trump International Tower in Chicago ranked 6th tallest building in world by Council on Tall Buildings & Urban Habitat http://bit.ly/sqvQq\n",
            "Wishing you and yours a very Happy and Bountiful Thanksgiving!\n",
            "Donald Trump Partners with TV1 on New Reality Series Entitled, Omarosa's Ultimate Merger: http://tinyurl.com/yk5m3lc\n",
            "--Work has begun, ahead of schedule, to build the greatest golf course in history: Trump International – Scotland.\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39xkDHEtovk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize tweets\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "examples = []\n",
        "for tweet in tweets:\n",
        "  tweet = \"[CLS]\" + tweet + \"[SEP]\"\n",
        "  tokenized = tokenizer.tokenize(tweet)\n",
        "  while len(tokenized) < MAX_TWEET_LENGTH:\n",
        "    tokenized.append(tokenizer.pad_token)\n",
        "  tokenized_ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
        "  examples.append(tokenized_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKOoHmEhtvPA",
        "colab_type": "code",
        "outputId": "01a77a90-5b00-4d8b-8f3a-8c3bf0436900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load model etc.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKxmO7MkuBWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimization parameters\n",
        "lr = 1e-3\n",
        "max_grad_norm = 1.0\n",
        "num_total_steps = 1000\n",
        "num_warmup_steps = 100\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n",
        "\n",
        "optimizerG = AdamW(model.parameters(), lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
        "schedulerG = WarmupLinearSchedule(optimizerG, warmup_steps=num_warmup_steps, t_total=num_total_steps)  # PyTorch scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtPtsHY5uUXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mask parts of a tweet, adapted from https://github.com/huggingface/pytorch-transformers/blob/master/examples/run_lm_finetuning.py\n",
        "def mask_tokens(inputs, tokenizer):\n",
        "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
        "    labels = inputs.clone()\n",
        "    for i in range(len(inputs)):\n",
        "      irow = inputs[i]\n",
        "      lrow = labels[i]\n",
        "      \n",
        "      # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
        "      pad_start = 0\n",
        "      for j in range(len(irow)):\n",
        "        if irow[j] == tokenizer.convert_tokens_to_ids(tokenizer.pad_token):\n",
        "          pad_start = j\n",
        "          break\n",
        "      masked_indices = torch.bernoulli(torch.full((pad_start,), 0.25)).to(torch.bool)\n",
        "      for j in range(len(lrow)):\n",
        "        if j >= pad_start or not masked_indices[j]:\n",
        "          lrow[j] = -1\n",
        "      #print(lrow)\n",
        "      #print(masked_indices)\n",
        "\n",
        "      # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "      indices_replaced = torch.bernoulli(torch.full((pad_start,), 0.8)).to(torch.bool)\n",
        "      for j in range(pad_start):\n",
        "        if indices_replaced[j] and masked_indices[j]:\n",
        "          irow[j] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "      #print(irow)\n",
        "\n",
        "      # 10% of the time, we replace masked input tokens with random word\n",
        "      indices_random = torch.bernoulli(torch.full((pad_start,), 0.5)).to(torch.bool)\n",
        "      for j in range(pad_start):\n",
        "        if indices_random[j] and not indices_replaced[j] and masked_indices[j]:\n",
        "          irow[j] = np.random.randint(len(tokenizer))\n",
        "      #print(irow)\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqIi5FOW9YXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(inputs, outputs, labels):\n",
        "  predictions = []\n",
        "  for j in range(len(inputs)):\n",
        "    prediction = []\n",
        "    for k in range(len(inputs[j])):\n",
        "      if labels[j][k] == -1:\n",
        "        prediction.append(inputs[j][k].item())\n",
        "      else:\n",
        "        predicted_index = torch.argmax(outputs[j][k]).item()\n",
        "        prediction.append(predicted_index)\n",
        "    predictions.append(prediction)\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtninVUv7FDV",
        "colab_type": "code",
        "outputId": "cdcfcbf0-3d7e-4ce2-a0fc-c4023c730673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 50\n",
        "batch_size = 25\n",
        "print_interval = 5\n",
        "print_size = 1\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "for i in range(num_epochs):\n",
        "  permuted_examples = list(np.random.permutation(examples))\n",
        "  for batch_start in range(0, len(permuted_examples) - batch_size, batch_size):\n",
        "    batch_end = batch_start + batch_size\n",
        "  batch = permuted_examples[:batch_size]\n",
        "  inputs = torch.as_tensor(batch, dtype=torch.int64)\n",
        "  inputs, labels = mask_tokens(inputs, tokenizer)\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  model.train()\n",
        "  outputs = model(inputs, masked_lm_labels=labels)\n",
        "  loss = outputs[0]\n",
        "  loss.backward()\n",
        "  torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "  optimizerG.step()\n",
        "  schedulerG.step()\n",
        "  optimizerG.zero_grad()\n",
        "  print(str(i + 1) + \"/\" + str(num_epochs) + \" epochs\")\n",
        "  print(\"loss: \" + str(loss.item()))\n",
        "  if (i + 1) % print_interval == 0:\n",
        "    print(\"sample predictions:\")\n",
        "    predictions = predict(inputs, outputs[1], labels)\n",
        "    for j in range(min(batch_size, print_size)):\n",
        "      print(\"original : \" + tokenizer.decode(batch[j], skip_special_tokens=True))\n",
        "      print(\"predicted: \" + tokenizer.decode(predictions[j], skip_special_tokens=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training Loop...\n",
            "1/200 epochs\n",
            "loss: 5.813612937927246\n",
            "sample predictions:\n",
            "original : remember,'ll you in.. at the building on wednesday at 1 00 o then on sept. 14 navarre : 00. m. air\n",
            "predicted: remember, i'll see you in c. m. at the school building on wednesday at 1 : 00 o... then, on sept. 14, navarre : 00 p. m. by air.\n",
            "2/200 epochs\n",
            "loss: 5.5091552734375\n",
            "sample predictions:\n",
            "original : jon _ senior : mr trump sir 1940s degree many presidents from last 50 years will be better than become? all? \" all!\n",
            "predicted: , ) : jon _ senior : mr trump sir - \" many presidents from the last 50 years will not be better than they or become \"? all \" \"? \" all! \"\n",
            "3/200 epochs\n",
            "loss: 5.355169773101807\n",
            "sample predictions:\n",
            "original : stories in the center of downtown york, trumpsoho ’ s 39 spacious rooms have - ceiling windows http : / / t northeastern co /zfoq intelligence\n",
            "predicted: the stories in the center of downtown new york, \" trumpsoho ’ s 39 \" spacious \", have - - - - ceiling windows http : / / t @ co / : tzfoq @.\n",
            "4/200 epochs\n",
            "loss: 5.443337440490723\n",
            "sample predictions:\n",
            "original : \" @msgt7 : @ realdonaldp get why you't goldberg. self - word smith \" true with zero talent. @ nr\n",
            "predicted: \" @ tmsgt.h7 : @ realdonaldeep i get why you don't like goldberg. @ @ self - proclaimed word smith. \" true @, with zero talent. @ nr.\n",
            "5/200 epochs\n",
            "loss: 5.378204822540283\n",
            "sample predictions:\n",
            "original : via @ : \" miss culpo miss universe ratings increase 15 % over last year. http / t. / wzlt2 admit\n",
            "predicted: via @ com : \" miss universe /,lpo, - miss universe \" ratings increase 15 % over last year. http : / / t. tv / wzlt2. /\n",
            "6/200 epochs\n",
            "loss: 4.368248462677002\n",
            "sample predictions:\n",
            "original : rt erictrum : congratulationsnity! lookingga to being on the show tonight at 9pmetnity madw - politic : گ …\n",
            "predicted: rtl erictrump : congratulations on andcnity! looking forward to being on the show tonight at 9pmetunnity. maddow - pol -op : \" …\n",
            "7/200 epochs\n",
            "loss: 5.305550575256348\n",
            "sample predictions:\n",
            "original : really bad article about me in dying ( or dead ) esquire magazine zipper totally false - lots of hatred. when will this boring magazine close?\n",
            "predicted: really bad article about me in the dying ( or dead ) esquire magazine is totally false - lots of hatred. when will this boring magazine close? \"\n",
            "8/200 epochs\n",
            "loss: 4.920054912567139\n",
            "sample predictions:\n",
            "original : i am temperate japan & ; south korea to a substantially increased amount of military equipment from the united longed\n",
            "predicted: i am asking japan & china ; south korea to get a substantially increased amount of new and military equipment from the united states.\n",
            "9/200 epochs\n",
            "loss: 4.518665790557861\n",
            "sample predictions:\n",
            "original : “ go theular so people will not to mess with you. ” – think big\n",
            "predicted: “ go to the insular so that people here will not want to mess with you. ” – think big\n",
            "10/200 epochs\n",
            "loss: 4.544217586517334\n",
            "sample predictions:\n",
            "original : @26ther, work hard in school!\n",
            "predicted: @7269therp, work hard in school!\n",
            "11/200 epochs\n",
            "loss: 4.714842319488525\n",
            "sample predictions:\n",
            "original : looking forward to meeting with @ senbobcorker in a little while. we will be traveling to cord carolina together today.\n",
            "predicted: looking forward to meeting with @ senbobcorker in a little while. we will be traveling to south carolina together today.\n",
            "12/200 epochs\n",
            "loss: 4.6355366706848145\n",
            "sample predictions:\n",
            "original : \" @ runpuremichigan macy'stock drops coming out in support of #s dust up with @ realdontrump and public # sheridanmacyslten\n",
            "predicted: \" @ runpuremichigan macy's stock., coming out in support of # cos dust up with @ realdonaldtrump and public # tmacy.\n",
            "13/200 epochs\n",
            "loss: 4.50738000869751\n",
            "sample predictions:\n",
            "original : \" theguief transported : @ realdonaldtrum # donaldtrumorpresident2016\n",
            "predicted: \" @ thegu3ief @ : @ realdonaldtrump # donaldtrumporpresident2016\n",
            "14/200 epochs\n",
            "loss: 4.528440475463867\n",
            "sample predictions:\n",
            "original : \" @ bclew70 : @ realdonaldtrump donald i am disappointed in you you should ran for pres \" late!\n",
            "predicted: \" @ bclew70 : @ realdonaldtrump donald i am disappointed in you. you should have ran for pres. \" @ @ late!\n",
            "15/200 epochs\n",
            "loss: 4.654220104217529\n",
            "sample predictions:\n",
            "original : @ciaa thanks.\n",
            "predicted: @ vaciadona thanks you.\n",
            "16/200 epochs\n",
            "loss: 4.261630535125732\n",
            "sample predictions:\n",
            "original : \" @ backontrackusa while is partying the wh corrupt african, christians are being killed isis american legendary\n",
            "predicted: \" @ backontrackusa : while he is partying to the wh. corrupt african leaders, christians are being killed by isis. american is real.\n",
            "17/200 epochs\n",
            "loss: 5.233883380889893\n",
            "sample predictions:\n",
            "original : to @ trumpnewyork and trumponto for ponds @sj coverage on per in luxury hotels http /. / wy6idgjc3c\n",
            "predicted: thanks to @ trumpnewyork and @ trumpdmonto for. @ posj coverage on peris in luxury hotels. http : /. \". \" / wy6idgjc3c\n",
            "18/200 epochs\n",
            "loss: 4.361815452575684\n",
            "sample predictions:\n",
            "original : @ lmoe : @ realtrump plslp my grandaughter stacey7 she has cancer & ; we need to 500k for outside uk.\n",
            "predicted: \" @ lmorpe : @ realaldaldtrump pls.lp my grandaughter stacey7 she has cancer & it ; we need to give 500k for the outside uk.\n",
            "19/200 epochs\n",
            "loss: 4.3465423583984375\n",
            "sample predictions:\n",
            "original : \" @ kyleweaverr : @ realdonaldtrump when is celebrity apprentice back? i'going through withdrawal # soonplease \" soon!\n",
            "predicted: \" @ kyleweaverr : @ realdonaldtrump when is @ celebrity apprentice coming back? i'm going through withdrawal. # soonplease \" soon!\n",
            "20/200 epochs\n",
            "loss: 4.292272567749023\n",
            "sample predictions:\n",
            "original : https : / /. co / tfrmzarwq\n",
            "predicted: https : / / t co / tfrmzajrwq\n",
            "21/200 epochs\n",
            "loss: 5.274679660797119\n",
            "sample predictions:\n",
            "original : @ thomasbrennan01 great architect lucknow\n",
            "predicted: @ thomasbrennan01 great architect @\n",
            "22/200 epochs\n",
            "loss: 5.469663619995117\n",
            "sample predictions:\n",
            "original : \" @ abtn @ realdonp our souza are trained to a 7 62mm through flea ass from 1000eres not fight a virus \"\n",
            "predicted: \" @ ab gmtn : @ realdontrum gop our leaders are trained to have a 7 - 62mm through a flea - ass from 1000 will not fight a virus \"\n",
            "23/200 epochs\n",
            "loss: 5.477525234222412\n",
            "sample predictions:\n",
            "original : \" @ pandorasandy1 : @ realdonaldtrump we donald make america great again question! \"!\n",
            "predicted: \" @ pandorasandy1 : @ realdonaldtrump we will donaldpp make america great again,! \" \" true!\n",
            "24/200 epochs\n",
            "loss: 6.05434513092041\n",
            "sample predictions:\n",
            "original : [unused488] i anticipated,∆ roberts the cover of time magazine. the liberal loves him - - should be ashamed.\n",
            "predicted: what i anticipated, he roberts with the cover of time magazine ). the liberal person that loves him - - he should be ashamed.\n",
            "25/200 epochs\n",
            "loss: 4.772635459899902\n",
            "sample predictions:\n",
            "original : @passmore thanks.\n",
            "predicted: @ trumppassmore thanks.\n",
            "26/200 epochs\n",
            "loss: 5.8518476486206055\n",
            "sample predictions:\n",
            "original : via @ ap \" misslp is crowned miss \" increase over last. http : / t. / wlt2so\n",
            "predicted: via @ ap : \" missususjlpo is crowned miss. \" an increase,, over last time. http : / / t. co / wjlt2soj\n",
            "27/200 epochs\n",
            "loss: 4.653828144073486\n",
            "sample predictions:\n",
            "original : # fullrepe stopping obama is now up the american. we elect mitney november\n",
            "predicted: # fullrepe, without stopping obama who is now up in the american people. we a elect @ mitserney in november\n",
            "28/200 epochs\n",
            "loss: 5.386536121368408\n",
            "sample predictions:\n",
            "original : @9862ander : @ brandiglanville @etano @ realdonaldtrump @ msvivicafox @ leezagibbons nbc stay on reinforcement of @plmy. she s got to go\n",
            "predicted: \" @ trump9862ander : @ brandiglanville @trum : @ realdonaldtrump @ msvivicafox @ leezagibbons @ nbc stay on. of @ kplicemya. she's got to go\n",
            "29/200 epochs\n",
            "loss: 6.062426567077637\n",
            "sample predictions:\n",
            "original : ##tainable - barackreateama has increased total federal budget out over 24 % during his 2006 http : / / t co / lc7q9 loves debt.\n",
            "predicted: # @ trumptainable - @ barackdonama has increased total federal budget out of of. over 24 % during his. http : / / t. co / lc7qq97 he loves debt.\n",
            "30/200 epochs\n",
            "loss: 5.3636040687561035\n",
            "sample predictions:\n",
            "original : new poll by abc news / post 32 carson 22 rubio bush 7, will the media put a negative spin on one?\n",
            "predicted: new poll by abc news / : post : 32 carson 22 rubio : bush 7., : will the media put a negative. on. one? :\n",
            "31/200 epochs\n",
            "loss: 5.3451619148254395\n",
            "sample predictions:\n",
            "original : certain republicans who lost to would rather save face by fighting me u s. court get proper. sad\n",
            "predicted: certain republicans who i lost to obama would rather save face by fighting me and. the u. s.. court get proper again. sad.\n",
            "32/200 epochs\n",
            "loss: 4.804380416870117\n",
            "sample predictions:\n",
            "original : \" @foxnews : @ danaperр @ynkelly @donaldtrum cyclist. the only real capitalist you honestly vote for.\n",
            "predicted: \" @ realfoxnews : @ danaperp @ lynkelly @ realdonaldtrump. the only real capitalist you will honestly vote for.\n",
            "33/200 epochs\n",
            "loss: 5.734677314758301\n",
            "sample predictions:\n",
            "original : \" derekcar need to wake up mr trump. you are the most person to run president the united states. # truth \"\n",
            "predicted: \" @ derekcarp \" i need to wake up mr donald trump. you are the most successful person to to run for president to the united states. # truth \"\n",
            "34/200 epochs\n",
            "loss: 6.4031829833984375\n",
            "sample predictions:\n",
            "original : @ holtzworth : @donaldp sarah palin defends donald trump's immigration plan on fox news https : / /. co / ihaciyus via @ youtube attends\n",
            "predicted: \" @ / / holtzworth : @ @donaldp sarah palin defends trump's / plan on fox news https : / / /. co / ihaciy /us via @ youtube.\n",
            "35/200 epochs\n",
            "loss: 6.086373329162598\n",
            "sample predictions:\n",
            "original : # icymi : announcement of air traffic control initiative : / / t. co / imizr22ga\n",
            "predicted: # icymi : announcement of air traffic control initiative : / / t. co / imizr22ga trump\n",
            "36/200 epochs\n",
            "loss: 6.44589376449585\n",
            "sample predictions:\n",
            "original : \" @ roniseale : big leadsང the people's potus # 2016gopnomination # trump20 #americaata http : /. co / it7psmwv!\n",
            "predicted: \" @ roniseale : big leads in the people's potus # 2016gopnomination # trump20trum #trumametrumdonatatrum http : @ / s. co / it7trumpsmwv @ @!\n",
            "37/200 epochs\n",
            "loss: 7.066388130187988\n",
            "sample predictions:\n",
            "original : my announcement is tomorrow!\n",
            "predicted: my announcement is tomorrow!\n",
            "38/200 epochs\n",
            "loss: 7.124693870544434\n",
            "sample predictions:\n",
            "original : everybody loves @ bretmichaels! he ’ a great and this is where he should be he agrees!\n",
            "predicted: everybody loves @ bretmichaels! he ’'a great. and this is where he should be all he agrees!\n",
            "39/200 epochs\n",
            "loss: 6.914356231689453\n",
            "sample predictions:\n",
            "original : @ heatherchilders you are doing a great job!\n",
            "predicted: @ heatherchilders you are doing a great job.!\n",
            "40/200 epochs\n",
            "loss: 6.772335529327393\n",
            "sample predictions:\n",
            "original : \" @4t : preach @ realtrump!! it on @ mikeke #estadepinga \"\n",
            "predicted: \" @ in4. : preach @ real in.trump!! in in in it on @ in in.ke in #estadepinga \"\n",
            "41/200 epochs\n",
            "loss: 7.334359169006348\n",
            "sample predictions:\n",
            "original : \" @ kunle _ jimber @ realaldtrump i one your \" \" such a nice brand mortal \" greatx\n",
            "predicted: \" @ kunle _ jimber @ real :aldtrump ivv onev your \" such a nice brand \" great7vx\n",
            "42/200 epochs\n",
            "loss: 7.41061544418335\n",
            "sample predictions:\n",
            "original : \" joenbc : cruz really seems out his element magnus new. wing is such a different battlefield then iowa and raiding south \"\n",
            "predicted: \" @ joenbc : cruz really seems out @ his element @ new @. @ is such a different battlefield then iowa and @ south @ \" @\n",
            "43/200 epochs\n",
            "loss: 7.739150047302246\n",
            "sample predictions:\n",
            "original : wow — golf magazine just [unused674] iphone scotland “ best course. ” http : / /. co / vv1iqu\n",
            "predicted: wow golf magazine just scotland “ best course. ” http : / /. co / vv1iqu\n",
            "44/200 epochs\n",
            "loss: 7.580835819244385\n",
            "sample predictions:\n",
            "original : \" @bruce : @ realdonald remember how awkward chevy was on short lived talk show? \" but he was better than @ sethmeyers.\n",
            "predicted: \" @.bruce : @ realdonald.. remember how awkward chevy. was ondon short lived talk show? \" but. was better than @ sethmeyers.\n",
            "45/200 epochs\n",
            "loss: 7.522719860076904\n",
            "sample predictions:\n",
            "original : an individual, whole career is trying to take down successful celebrities with nonsense campaigns, has turned his attention to me.mina... roundabout\n",
            "predicted: an individual, trump whole career is trying to take down successful celebrities with nonsense campaigns, has turned his attention to me. trump... trump\n",
            "46/200 epochs\n",
            "loss: 7.595211029052734\n",
            "sample predictions:\n",
            "original : \" @ mattyms : @donaldtrump it's. the warrior present can give is to my president \" happy birthday!\n",
            "predicted: / \" @ /yms : @ /donaldtrump it's / / /. the / present / / give / is to / my / president / \" happy birthday!\n",
            "47/200 epochs\n",
            "loss: 7.268346309661865\n",
            "sample predictions:\n",
            "original : forward to being & amp ; interviewed monday david rubenstein at the @ theeconomiccl http : / t. co / 1psf18lsp\n",
            "predicted: to being & amp ; interviewed david rubenstein at the @ theeomiccl http : / t. co / 1psf8lsp\n",
            "48/200 epochs\n",
            "loss: 7.371478080749512\n",
            "sample predictions:\n",
            "original : \" @ cbauer71 : i would see @ resemblesdonaldp debate # obama!! \"!\n",
            "predicted: \" @ cbauer71 : i would \". see @ \"donald @p debate # obama!! \" @ @ \"!.\n",
            "49/200 epochs\n",
            "loss: 7.314266204833984\n",
            "sample predictions:\n",
            "original : . @clinton been doing this for thirty years... where has she? bigleatruth\n",
            "predicted: . @trumclintontrum been doing this for thirty years.. @. where has she @?trum biglea @truth\n",
            "50/200 epochs\n",
            "loss: 7.482844829559326\n",
            "sample predictions:\n",
            "original : stuart stevens is a dumb guy who fails @ virtually everything he touches. campaign, his book, etc. why does @ andersoncooper him?\n",
            "predicted: stuart stevens is a dumb guy who fails @ virtually everything he touches.. campaign, his book, etc. why does @ andersoncooper. him.?.\n",
            "51/200 epochs\n",
            "loss: 7.339475631713867\n",
            "sample predictions:\n",
            "original : to on signing long the @ mets. david is an exceptional player and person.\n",
            "predicted: i to i i on signing i long i i i the @ mets. david is an exceptional player and person.\n",
            "52/200 epochs\n",
            "loss: 7.275626182556152\n",
            "sample predictions:\n",
            "original : entrepreneurs : gain and use information to your advantage - - see dayrnet opportunity to learn.\n",
            "predicted: entrepreneurs : gain @ use information to your advantage - - see. day.. opportunity to learn.\n",
            "53/200 epochs\n",
            "loss: 7.1560444831848145\n",
            "sample predictions:\n",
            "original : required reading 4 success ryder politics amp ; life read @guilfoyle'sated #thecase advice! http : / /. deteriorating / f64q 1918w4v donate\n",
            "predicted: required reading 4 success @ politics @ amp ; life @ @ @guilf @le's @ # @thecase @ @ advice! http : / / @. @ / f64q @w4 @v @\n",
            "54/200 epochs\n",
            "loss: 7.089370250701904\n",
            "sample predictions:\n",
            "original : \", grant that always desire more than i can accomplish. \" - michelangelo\n",
            "predicted: \" \", grant that \" always desire more than i can accomplish. \" - michelangelo\n",
            "55/200 epochs\n",
            "loss: 6.707690238952637\n",
            "sample predictions:\n",
            "original : \" @ wayway1 : @ realdontrump webb is presumably!! \" bad chair # dembate\n",
            "predicted: \" @ wayway co1 : @ realdon thetrump webb is /!! \" bad the # dem thebate\n",
            "56/200 epochs\n",
            "loss: 7.423642635345459\n",
            "sample predictions:\n",
            "original : \" @ane : @dontrump # trump\n",
            "predicted: \" @.ane. : @.don.trump # trump...\n",
            "57/200 epochs\n",
            "loss: 6.886791229248047\n",
            "sample predictions:\n",
            "original : @bin.\n",
            "predicted: @...bin...\n",
            "58/200 epochs\n",
            "loss: 6.859063148498535\n",
            "sample predictions:\n",
            "original : great chris rudd @ newsmax _ media : \" @ anndromney jackie'\" http : /lowe. co juytnxdt\n",
            "predicted: great,. chris rudd. @ news _ media : \" @ anndromney. jackie '.. \" http : / : :. co. :ytnxdt\n",
            "59/200 epochs\n",
            "loss: 7.245794773101807\n",
            "sample predictions:\n",
            "original : anybody ( especially fake news media ) who thinks repeal & amp ; replace obamacare is does not know the love and cheltenham!\n",
            "predicted: @ anybody ( especially fake news @ ) who thinks, repeal & amp ; replace, obamacare is @ does not know the love and @ @ @ @!\n",
            "60/200 epochs\n",
            "loss: 6.8742241859436035\n",
            "sample predictions:\n",
            "original : millions without electricity across & amp ; nj the media has covered obama s massive failure. can you imagine if this was another pres?\n",
            "predicted: millions without electricity across @ & amp ; nj @ the media has covered @ obama @ s massive failure. can you imagine if this was another pres?\n",
            "61/200 epochs\n",
            "loss: 7.30049467086792\n",
            "sample predictions:\n",
            "original : \" @ pbs successeswo : @ realdontrump @ hyannis1952 @ foxne sarawak the donald nothingists. he could restore our republic \" true overdose\n",
            "predicted: \" @ pbs \"wo : @ realdon \"trump @ hyannis1952 @ foxne \" the donald \" nothing \" \"ists. he could restore our republic \" \" true \"\n",
            "62/200 epochs\n",
            "loss: 7.094364643096924\n",
            "sample predictions:\n",
            "original : we're going to use american steel we're going orbiting american labor, we are going to come first in all. … https / /. co / qyj9kyy\n",
            "predicted: we're going to use american steel we're going american labor, we are going to come first in all. … https / /. co / qyj \" \"9k \"yy\n",
            "63/200 epochs\n",
            "loss: 6.876780986785889\n",
            "sample predictions:\n",
            "original : i hope you canshire @ orefactor for trump to make america great again! thanks.\n",
            "predicted: i hope you can \" \" @ ore \"factor \" for \" trump \" \" to make america great again! thanks.\n",
            "64/200 epochs\n",
            "loss: 6.920187950134277\n",
            "sample predictions:\n",
            "original : acclaimed @ trumpchicago soars stories high. you ’ re either in @ trumpchicago in. http : / / t.grantswsz\n",
            "predicted: . acclaimed @ trumpchica. soars. stories high. you ’ re either. in @ trumpchicago. in... http : / / t.....ws..z\n",
            "65/200 epochs\n",
            "loss: 7.012271881103516\n",
            "sample predictions:\n",
            "original : \" markg0077 @bon @ realdonaldtrump but, we put our trust @ mittromney and he failed म\n",
            "predicted: \". markg00.7...bon. @.donaldtrump but., we put our trust. @ mittromney and he failed...\n",
            "66/200 epochs\n",
            "loss: 6.619617462158203\n",
            "sample predictions:\n",
            "original : \"making irwin171 : celebapprentice turned me into a @ kevinjonas fan. love the new season!!donaldtrump\n",
            "predicted: .. irwin171 :. celebapprentice. turned me into a @ kevinjonas fan. love the new season!!...aldtrump..\n",
            "67/200 epochs\n",
            "loss: 7.469985008239746\n",
            "sample predictions:\n",
            "original : @ mj7 thanks!\n",
            "predicted: @ mj7 thanks!\n",
            "68/200 epochs\n",
            "loss: 6.8465895652771\n",
            "sample predictions:\n",
            "original : @ mittromney has most delegates, received the most votes and the most states. the primary over. time to defeat @ barackobama.\n",
            "predicted: @ mitney has most delegates, received the most votes and the most states. the primary over. time to defeat @ barackobama.\n",
            "69/200 epochs\n",
            "loss: 6.993293285369873\n",
            "sample predictions:\n",
            "original : i will on @andiends at 7 : 00 a. m. enjoy!\n",
            "predicted: i will. on @.and.iends at 7 : 00 a. m. enjoy!\n",
            "70/200 epochs\n",
            "loss: 7.0460638999938965\n",
            "sample predictions:\n",
            "original : mimi _ saul :cl8 @ realdonald jeb supports open borders - common core - visa h - ib visa's for illegals. super pac saudis.\n",
            "predicted: @ @ @ _ saul. :. @cl @8 @ @ realdonald @. jeb supports open borders - common core - visa h - ib visa's for illegal @. super pac saudis.\n",
            "71/200 epochs\n",
            "loss: 6.930991172790527\n",
            "sample predictions:\n",
            "original : \" @ benbrice : @ realdonaldtrump how s progress on the scottish golf course coming? # interested \" finished and great.\n",
            "predicted: \" @ benbrice @ : @ realdonaldtrump how @ s progress on the scottish golf course coming @? # interested \" finished and great.\n",
            "72/200 epochs\n",
            "loss: 6.8937554359436035\n",
            "sample predictions:\n",
            "original : rt @ thetles : @ realdonaldtrump president trump will win in in an even bigger landslide than! you are greatest president\n",
            "predicted: @ @ the.tle.s : @ realdonaldtrump president trump will win in. in an even bigger landslide than.! you are @ greatest president..\n",
            "73/200 epochs\n",
            "loss: 7.221798896789551\n",
            "sample predictions:\n",
            "original : @ uswstravel @chicago'amp ; rooms make feel like they're livin'the life :™ / / t co 1661 qk8ivi9 \"\n",
            "predicted: . @ us.wstravel.. @.chicago '... amp ;. rooms make. feel like they're livin'the. life :.. / / t. co. qk8.ivi9. \"\n",
            "74/200 epochs\n",
            "loss: 7.200455188751221\n",
            "sample predictions:\n",
            "original : getting ready prime minister abe of truly fine gentleman!\n",
            "predicted: . getting ready.. prime minister abe of... truly fine gentleman!.\n",
            "75/200 epochs\n",
            "loss: 6.577195167541504\n",
            "sample predictions:\n",
            "original : \" @ car 95 have you written torwards adults / college students on how to be successful? \" think like champion rumor good startivate\n",
            "predicted: . \" @ car.... have you written. torwards. adults / college students on how to be successful? \" think like. champion.. good start.\n",
            "76/200 epochs\n",
            "loss: 6.6997880935668945\n",
            "sample predictions:\n",
            "original : let'[unused350] take a look at that birth siberian. barackobama was described 2003 as being \" born in kenya. \" http : / / co / vfqsjl\n",
            "predicted: . let '. take a look that birth... barackobama. described. 2003 as being \" born in kenya. \" http : / /.. co / vfq.s.l\n",
            "77/200 epochs\n",
            "loss: 6.883995056152344\n",
            "sample predictions:\n",
            "original : time - do you think had presentation? #barentice\n",
            "predicted: ... time -!. do you think had.. presentation? #..ba.rentice\n",
            "78/200 epochs\n",
            "loss: 6.977057456970215\n",
            "sample predictions:\n",
            "original : if stop & amp frisk is struck by the pandering nyc, increases insford & ; eventual attacks will be on them\n",
            "predicted: if stop & amp. frisk is struck. by the pandering nyc., increases in. &. ; eventual. attacks will be on them.\n",
            "79/200 epochs\n",
            "loss: 7.0421528816223145\n",
            "sample predictions:\n",
            "original : it's 10 am : two to for to easily up millions for charity\n",
            "predicted: it's 10 am : two. to. for. to easily. up millions. charity.\n",
            "80/200 epochs\n",
            "loss: 7.004584789276123\n",
            "sample predictions:\n",
            "original : \" @ticrim : dear @ megyn, your attempted hatchet job on realaldtrum wasbe & amp a total failure. @ foxws\n",
            "predicted: \" @.ti.crim : dear @ megyn.., your attempted hatchet job on. real.aldtrum. was.be. & amp. a total failure. @ fox.ws\n",
            "81/200 epochs\n",
            "loss: 6.518457889556885\n",
            "sample predictions:\n",
            "original : economic growth can save social, and america.\n",
            "predicted: economic growth can save social.,. and america.\n",
            "82/200 epochs\n",
            "loss: 7.180845737457275\n",
            "sample predictions:\n",
            "original : . @ 1570mstevent of endings a show missuniverse. standing o!\n",
            "predicted: . @mstevent.. of. endings. a show.. missuniverse. standing o!\n",
            "83/200 epochs\n",
            "loss: 6.904403209686279\n",
            "sample predictions:\n",
            "original : joshj4 \" realdonaldtrump have that you will be president to make this country great again. # usa \" thank you carlson\n",
            "predicted: josh.j4 \". realdonaldtrump. have.. that you will be president to make this country great again. # usa \" thank you..\n",
            "84/200 epochs\n",
            "loss: 7.078999042510986\n",
            "sample predictions:\n",
            "original : they say if last night s debate, they would have had 12 more & ; would have the germans troy record.\n",
            "predicted: they say..... last night. s. debate, they would have had 12.. &. ; would have. the.. record..\n",
            "85/200 epochs\n",
            "loss: 7.065591812133789\n",
            "sample predictions:\n",
            "original : i would to a great writer and, designation jpapppr.rae of real estate weekly, for the wonderful story on me. very appreciated!\n",
            "predicted: . i would. to. a great writer and.,. jpapp.pr.. of real estate weekly, for the wonderful story on.. very. appreciated!.\n",
            "86/200 epochs\n",
            "loss: 6.804777145385742\n",
            "sample predictions:\n",
            "original : i had amazing time in charlotte. temperance emeritus amp many new friends i look forward to coming back soon. congrat to & amp staff.\n",
            "predicted: . i had amazing time in charlotte...... many new friends. i look forward to coming back. soon. congrat. to. & amp. staff.\n",
            "87/200 epochs\n",
            "loss: 6.6955461502075195\n",
            "sample predictions:\n",
            "original : joelbernstein @dontrump @ tyler _ tuscchevy only does america need an adult dc we djt in 2016 \" you.\n",
            "predicted: .. joelbernstein. @.don.trump @ tyler _ tuscchevy. only does america need an adult. dc we. djt in 2016 \". you.\n",
            "88/200 epochs\n",
            "loss: 7.008079528808594\n",
            "sample predictions:\n",
            "original : i will interviewed on @ facethenation this. enjoy! @ jdickerson\n",
            "predicted: i will. interviewed on @ facethenation this.. enjoy! @ jdickerson\n",
            "89/200 epochs\n",
            "loss: 6.956936359405518\n",
            "sample predictions:\n",
            "original : “ if you about endeavors, it will back to provision. ” trump never discrete up\n",
            "predicted: “ if you.. about. endeavors, it will.. back to...... ”. trump never. up\n",
            "90/200 epochs\n",
            "loss: 6.722784042358398\n",
            "sample predictions:\n",
            "original : barackob should pressuring israel against defending iran worry how will stop the nuclear drive\n",
            "predicted: .. barackob. should. pressuring israel against. iran. worry how. will stop the........\n",
            "91/200 epochs\n",
            "loss: 6.761468887329102\n",
            "sample predictions:\n",
            "original : the unafford care act sometimes referred ascare, is not working millions of are their plans and doctors fraud!\n",
            "predicted: the unafford. care act. sometimes referred. as.care, is not working. millions of. are. their plans and.. fraud!\n",
            "92/200 epochs\n",
            "loss: 7.20575475692749\n",
            "sample predictions:\n",
            "original : . redcross ceo ’ s in 2011 was $ 95, 957. where is the outrage\n",
            "predicted: .. red. ceo ’ s. in 2011 was $ 95., 957. where is the outrage.\n",
            "93/200 epochs\n",
            "loss: 6.805502414703369\n",
            "sample predictions:\n",
            "original : negotiation pouring think about what the other side wants know where they're coming from. to create a win win.\n",
            "predicted: negotiation.. think about what the other side wants. know where they're coming from.. to create a win. win...\n",
            "94/200 epochs\n",
            "loss: 7.0755414962768555\n",
            "sample predictions:\n",
            "original : \" harder you,iring it is to surrender. \" - @ profballhof @bills head coach marv\n",
            "predicted: \". harder you.,.. it is to surrender... @ prof.ballhof @.bills head coach marv.\n",
            "95/200 epochs\n",
            "loss: 7.244403839111328\n",
            "sample predictions:\n",
            "original : \" tfle11 @ realdonaldtrump @ jijasm lived in chicago all my epsilon. looks great! \" [unused149]\n",
            "predicted: \". tfle @11 @ @ real @aldtrump @ jijas.m lived in chicago all my @.. looks great! \" @ @\n",
            "96/200 epochs\n",
            "loss: 6.616264343261719\n",
            "sample predictions:\n",
            "original : \" thebillmcgee @ realdonaldtrump - year of shirts still great! glad made the purchase! \" thank.\n",
            "predicted: \" thebillmcgee @ realdonaldtrump -.. year of.. shirts still. great! glad. made the purchase! \" thank..\n",
            "97/200 epochs\n",
            "loss: 6.725270748138428\n",
            "sample predictions:\n",
            "original : @ champagne sweeping : politico @ realdontrump card best\n",
            "predicted: . @ champagne.. :. politico. real..trump card.. best.\n",
            "98/200 epochs\n",
            "loss: 7.098977565765381\n",
            "sample predictions:\n",
            "original : @ agpt73 : @donaldtrump have helped me become who i am today. \".\n",
            "predicted: @ @ @ agpt73 @ @ @donaldtrump @ @ have helped me become who i am today. \" @. @\n",
            "99/200 epochs\n",
            "loss: 6.821446895599365\n",
            "sample predictions:\n",
            "original : rt @ erictrump : my family in this movement to #americagregain!! now it up to you! please # vote for america! https …\n",
            "predicted: rt @ erictrump : @ my family @ this @ movement to # @americagre @gain!! now it @ up to you! please # vote for america! https @ …\n",
            "100/200 epochs\n",
            "loss: 7.131695747375488\n",
            "sample predictions:\n",
            "original : happy birthday to @ fl, melania! https : t. co / ryyp activismmxdrcus : / t. co /7kyhglsv\n",
            "predicted: happy birthday to @ @ fl @ @, melania! https : @ @ t. co / ryyp @mxd @ @ : @ / t. co / @7kyhglsv\n",
            "101/200 epochs\n",
            "loss: 7.179256439208984\n",
            "sample predictions:\n",
            "original : if you fail once, twice,8, it doesn t matter learn from your mistakes and push forward victory - the sweet is!\n",
            "predicted: if you fail once, twice, @ @, it doesn @ t matter @ learn from your mistakes and push forward @ victory - the sweet @ @ @ is!\n",
            "102/200 epochs\n",
            "loss: 7.398478031158447\n",
            "sample predictions:\n",
            "original : \" @ dcfoaf : @ ianing @nbc @ realdonaldtrum wow sounds like something huge is about to hit next episode i't wait! \"\n",
            "predicted: \" @ dcfo.af. : @ ian.ing @.nbc @ realdon.trum. wow sounds like something huge is about to hit. next episode i.'t wait! \"\n",
            "103/200 epochs\n",
            "loss: 6.780880928039551\n",
            "sample predictions:\n",
            "original : i ’ ve a 10 - filled with8 master cases of food and supplies to my hometown of queens today # trumps\n",
            "predicted: i ’ ve. a 10 -. filled with.8 master cases of food and supplies. my hometown of queens. # trump.s\n",
            "104/200 epochs\n",
            "loss: 6.728041172027588\n",
            "sample predictions:\n",
            "original : @ datdudehead : we've got to do something this left wing regime whojima country go to donation. skill president\n",
            "predicted: .. @ datdudehead : we've got to do something. this left wing. regime who... country. to... president..\n",
            "105/200 epochs\n",
            "loss: 7.26682710647583\n",
            "sample predictions:\n",
            "original : @ zwlykins @ johnnypaulcole your upgrade has been granted & amp ; noted by front desk. have a wonderful time at trump international las.\n",
            "predicted: @ zwlykins @ johnnypaulcole your upgrade has. granted & amp ; noted by. front desk. have a wonderful time at trump international las..\n",
            "106/200 epochs\n",
            "loss: 7.355173110961914\n",
            "sample predictions:\n",
            "original : you have to be patient as enthusiastic when comes to your goals bowler big, but be realistic. ” – think big\n",
            "predicted: . you have to be patient as.. enthusiastic when. comes to your goals.. big, but be realistic. ” – think big\n",
            "107/200 epochs\n",
            "loss: 6.882094383239746\n",
            "sample predictions:\n",
            "original : it's monday how many more excuses will obama today about economy?\n",
            "predicted: it's monday how many more excuses will obama today about economy?\n",
            "108/200 epochs\n",
            "loss: 6.620316028594971\n",
            "sample predictions:\n",
            "original : \" @ikal69 : @ realaldtrump do you think @ billmah cancel? \" i don 1655 t think of billher - and nobody does.\n",
            "predicted: \" @ikal69 : @ realaldtrump do you think @ billmah? \" i don t think of billher - and nobody does.\n",
            "109/200 epochs\n",
            "loss: 6.66477632522583\n",
            "sample predictions:\n",
            "original : obama once said he “ would sh law ” by granting amnesty through executive action now he ’ s about it what will congress\n",
            "predicted: obama once said he “ would law ” by granting amnesty through executive action now he ’ s about it what will congress\n",
            "110/200 epochs\n",
            "loss: 6.947628974914551\n",
            "sample predictions:\n",
            "original : is roger @ politicoro ever right anything? athletes he s @ billclinton in [unused387] of ( cont ) http : pedestrians /. co npsnosue\n",
            "predicted: is roger @ politicoro ever right anything? he s @ billclinton in of cont ) : /. co npsnosue\n",
            "111/200 epochs\n",
            "loss: 7.545989990234375\n",
            "sample predictions:\n",
            "original : \" @ jamesmock4 principled,, decisive leadership. i helmut. i see #16 mr trump. usa \"\n",
            "predicted: \" @ jamesmo4 principled,, decisive leadership. i. i see #16 mr trump. usa \"\n",
            "112/200 epochs\n",
            "loss: 6.7960100173950195\n",
            "sample predictions:\n",
            "original : @ necprof : @genengcollege is excited to donaldtrump for a town hall meeting on monday at 3 pm. orb urged / t co / o8c3ei # fitn nhpolitics\n",
            "predicted: @. necprof : @.engcollege is excited to. donaldtrump for a town @ meeting on monday at 3 pm... / @ t. co / o8c3ei... # fitn @ nhpolitics\n",
            "113/200 epochs\n",
            "loss: 6.7620110511779785\n",
            "sample predictions:\n",
            "original : : quick reminder your last to register to vote! https : /. co / zgnu8vcs https : / /f8ercztc1\n",
            "predicted: : quick reminder your last to register to vote! https : /. co zgnu8vcs https : / /f8ercztc1\n",
            "114/200 epochs\n",
            "loss: 6.706956386566162\n",
            "sample predictions:\n",
            "original : \" @ jeffman5 @reraaldtrump you are the!!\n",
            "predicted: \" @ jeff.man5. @..aldtrump. are the.!.!.\n",
            "115/200 epochs\n",
            "loss: 6.573862075805664\n",
            "sample predictions:\n",
            "original : be tough, be smart, be personable but don elderly things personally ’ s business. – think a\n",
            "predicted: .. be tough, be smart, be personable. don... things personally.. ’ s. business.. – think. a.\n",
            "116/200 epochs\n",
            "loss: 6.999228477478027\n",
            "sample predictions:\n",
            "original : \" @manjack : on fire today! he really have his finger on the pulse called thetrum shamers can'win against el rushbo\n",
            "predicted: \" @manjack : on fire today! he really have his on the pulse thetrum shamers can'win against el rushbo\n",
            "117/200 epochs\n",
            "loss: 6.7286458015441895\n",
            "sample predictions:\n",
            "original : @ mystntapt thanks rob and good luck.\n",
            "predicted: @ myst.ntapt thanks rob and good luck.\n",
            "118/200 epochs\n",
            "loss: 6.948862552642822\n",
            "sample predictions:\n",
            "original : . @ yusiiqui piersmorgan @ rustyrockets i got much better — no contest — i gotania!\n",
            "predicted: .. @ yusi.iqui. piersmorgan @ rustyrockets i got much better — no contest. i got.ania!\n",
            "119/200 epochs\n",
            "loss: 6.8830695152282715\n",
            "sample predictions:\n",
            "original : when will barackama his transcript? what is he hiding?\n",
            "predicted: . when will. barack.ama. his transcript.?. is he hiding?.\n",
            "120/200 epochs\n",
            "loss: 6.992066860198975\n",
            "sample predictions:\n",
            "original : watch the latest from the desk of trump at : / / bit. ly / f0km and read article http : / / nyn. us / fpkq\n",
            "predicted: watch the latest from the desk of. trump at. : / / bit. l. / f0km.. and read. article http : / / ny.n. us / fpkq.\n",
            "121/200 epochs\n",
            "loss: 6.554963111877441\n",
            "sample predictions:\n",
            "original : # benitomi : weekly 1849 / / workshops. co / ckvrestzga1 https / / t. co /gzlvls\n",
            "predicted: #.mi : weekly... / /.. co / ckv..zga1. https. / / t. co /.gzlvls..\n",
            "122/200 epochs\n",
            "loss: 6.557868957519531\n",
            "sample predictions:\n",
            "original : i will interviewed on @ mariabartiromo @ foxbusiness at 7 30 employ\n",
            "predicted: @ i will @ interviewed on @ mariabartiromo @ foxbusiness at 7 @ 30 @\n",
            "123/200 epochs\n",
            "loss: 6.943282604217529\n",
            "sample predictions:\n",
            "original : just few more until the 13th season of all star @leppice premieres sure to tune in sunday at 9pm on @ nbc. big!\n",
            "predicted: just @ few more. until the 13th season of all. star @le.pp.ice premieres. sure to tune in sunday at 9pm on @ nbc. big!\n",
            "124/200 epochs\n",
            "loss: 7.168021202087402\n",
            "sample predictions:\n",
            "original : “ don toss off your promotion, and don ’ t bags on them deal with them! ” – think a champion\n",
            "predicted: “ don.. toss off your., and don ’ t. on them... with them! ” – think. a champion\n",
            "125/200 epochs\n",
            "loss: 6.906601905822754\n",
            "sample predictions:\n",
            "original : striker for # missuniverse pageant were 4 years. @ nbc likes me and i like them! )\n",
            "predicted: . for # missuni. pageant were.. 4 years. @ nbc. me. and i like them! ).\n",
            "126/200 epochs\n",
            "loss: 6.683691024780273\n",
            "sample predictions:\n",
            "original : again, morela people voted in the last than enrolled in obama. congratulations america\n",
            "predicted: again, more. people voted in. last. than enrolled in obama.. congratulations america..\n",
            "127/200 epochs\n",
            "loss: 6.827788829803467\n",
            "sample predictions:\n",
            "original : the s & downgrade is direct result of @ama's increased reckless spending and obama care. he this.\n",
            "predicted: the s &. down. is. direct result of @..ama's increased reckless. spending and obama care. he. this.\n",
            "128/200 epochs\n",
            "loss: 6.643928527832031\n",
            "sample predictions:\n",
            "original : speech on veterans': https : /. co / xb sandrmwesmk\n",
            "predicted: speech on veterans '. : https :. /.. co / xb.rmwesmk\n",
            "129/200 epochs\n",
            "loss: 6.698308944702148\n",
            "sample predictions:\n",
            "original : thanks. https helium / / t. co qvdljtolq\n",
            "predicted: thanks. https. / / t. co. qvdljtolq.\n",
            "130/200 epochs\n",
            "loss: 6.979703903198242\n",
            "sample predictions:\n",
            "original : \"'ve got for expansive obama : america not what's wrong withores. \" # timetogetgh : / / /y6 indefinitec3 http : / / t. co / gnlqddd\n",
            "predicted: . \".'ve got. for. obama : america. not what. s wrong with... \" # timetoget.gh. : / /... /.y6.c.3 http : / / t. co / gnlqddd.\n",
            "131/200 epochs\n",
            "loss: 7.01663875579834\n",
            "sample predictions:\n",
            "original : will be interviewed on @ morning _ joe at 7 : 00 m. much talk about\n",
            "predicted: will be. on. morning _ joe at 7 : 00.. m.. much. talk about.\n",
            "132/200 epochs\n",
            "loss: 7.05027437210083\n",
            "sample predictions:\n",
            "original : \" @ mrbocce : @donaldtrump this red sox fan says let'em keep paying! boston. be very happy!\n",
            "predicted: \" @ mrbocce : @.don.trump this red sox fan says.'em keep paying! boston.. be very happy!\n",
            "133/200 epochs\n",
            "loss: 6.646012306213379\n",
            "sample predictions:\n",
            "original : agentvf : @ realdonaldtrump stay ready for next debate. great job night.\n",
            "predicted: .. agentvf : @ realdonaldtrump stay... ready. next debate. great job. night..\n",
            "134/200 epochs\n",
            "loss: 6.64656925201416\n",
            "sample predictions:\n",
            "original : 漢 @ide publish : realdontictrump what would be wheelbase than you buying lovely team and beating cuban team on a regular basis? who cares\n",
            "predicted: .. @..ide. :. realdon.trump what would be. than you buying.. team and beating cuban.. team on a regular.. who cares.\n",
            "135/200 epochs\n",
            "loss: 6.652542591094971\n",
            "sample predictions:\n",
            "original : @ ivankatp :. @ golfgestma predicts @ realdonaldtrump barrel's greatest builder today. # blue hutter # aberdeen #point \"\n",
            "predicted: .. @ ivankat.p :. @ golf.gestma. predicts. @.donaldtrump..'s greatest builder today. # blue.ter # aberdeen #.point \"\n",
            "136/200 epochs\n",
            "loss: 7.11777925491333\n",
            "sample predictions:\n",
            "original : \" @ mitchryanrocks : please run for office. this country ur leadership, knowledge, n passion d love to be a of ur team! \"\n",
            "predicted: \" @ mitchryanrocks : please run for office. this country. ur leadership, knowledge, n passion..... d love to be a. of ur team! \"\n",
            "137/200 epochs\n",
            "loss: 6.732732772827148\n",
            "sample predictions:\n",
            "original : . @tem talks about my hair i m allowed to about her ugly face or - - so i won't. is a double standard?\n",
            "predicted: . @.tem.. talks about my hair. i. m. allowed to. about her ugly face or. - -. so i won't. is. a double standard?\n",
            "138/200 epochs\n",
            "loss: 7.031198978424072\n",
            "sample predictions:\n",
            "original : \" @qville : hey @ realdonaldtrum i walked into the lobby of trump soho. by far the terribly hotel professional staff in roe \" thanks!\n",
            "predicted: \" @.qville : hey @ realdonaldtrum. i walked into the lobby of trump soho. by far the. hotel. professional staff in.. \" thanks!\n",
            "139/200 epochs\n",
            "loss: 6.898458957672119\n",
            "sample predictions:\n",
            "original : , the respected monmouth university has me ahead of most republican candidates nationwide, and people don't think'm running!\n",
            "predicted: ., the respected monmouth university. has me ahead of most republican candidates nationwide, and. people don't think.'m running!\n",
            "140/200 epochs\n",
            "loss: 7.114185333251953\n",
            "sample predictions:\n",
            "original : federal gov. has sandy worse than katrina. there is excuse why people cycle't have electricity or fuel yet\n",
            "predicted: . federal gov. has. sandy worse than katrina. there is. excuse why people.'t have electricity or fuel yet.\n",
            "141/200 epochs\n",
            "loss: 6.617851734161377\n",
            "sample predictions:\n",
            "original : \" @ tonene96 : realdonaldtrump no man or women on this planet can give us back america with the exception of @ realdonaldtrump leadership\n",
            "predicted: \" @ tone.ne96 :. realdonaldtrump no man or women on this planet can give us back america with the exception of @ realdonaldtrump leadership..\n",
            "142/200 epochs\n",
            "loss: 6.494418621063232\n",
            "sample predictions:\n",
            "original : they packers say char word thug is, like so many words, not politically correct ( even though obama uses it ) it is racist. bull\n",
            "predicted: they. say.. word. thug. is, like. many. words. not politically correct ( even though obama uses it ). it is racist. bull.\n",
            "143/200 epochs\n",
            "loss: 6.680441856384277\n",
            "sample predictions:\n",
            "original : \" aus constituencies bailey @ real feastaldtrump has the best tweets for. \" thank you, a great.\n",
            "predicted: \". aus.. bailey. @ real.aldtrump has the best tweets for.. \" thank you,. great....\n",
            "144/200 epochs\n",
            "loss: 7.113241672515869\n",
            "sample predictions:\n",
            "original : entrepreneurs : realize that fear is the exact opposite portsmouth faith. resolve be unsuitable your problems.'s the boss?\n",
            "predicted: entrepreneurs : realize. fear is the exact opposite. faith. resolve. be.. your problems..'s the.?\n",
            "145/200 epochs\n",
            "loss: 6.833662509918213\n",
            "sample predictions:\n",
            "original : trump university has % approval rating i could haveagawa 'deck of principle!\n",
            "predicted: . trump university has.. % approval rating. i could have... '.. of principle!.\n",
            "146/200 epochs\n",
            "loss: 7.025119304656982\n",
            "sample predictions:\n",
            "original : \" @onbeets : @ realdontrum you do anything the world better, what would do \" fire obama!\n",
            "predicted: \" @.on.ts : @ realdon.trum.. you. do anything.. the world.. better, what would. do. \" fire obama!.\n",
            "147/200 epochs\n",
            "loss: 6.736288070678711\n",
            "sample predictions:\n",
            "original : thank @ bill 1850illy amp ; @ karlrove ted burst should be disqualified in, each broadcasters moving up one notch.\n",
            "predicted: thank. @ bill.illy. amp. @ karlrove. ted. should be. disqualified in.,. each. moving up one notch.\n",
            "148/200 epochs\n",
            "loss: 6.4172139167785645\n",
            "sample predictions:\n",
            "original : \" @ jlkelly : @ realdontrump beautiful!! trump national golf course /nto t. co / vgducyoh5w \"\n",
            "predicted: . \" @ jlkelly. : @ realdon.trump beautiful!! trump national golf course... /. t. co / vgducyoh5w \"\n",
            "149/200 epochs\n",
            "loss: 6.662030220031738\n",
            "sample predictions:\n",
            "original : why do the continue to put do @ billkristol panels has called every single shot about me for 2 y?\n",
            "predicted: why do the. continue to put do.. @ billkristol. panels.. has called every single shot about me. for 2 y.?\n",
            "150/200 epochs\n",
            "loss: 6.671380996704102\n",
            "sample predictions:\n",
            "original : congress, use the power of the purse.!\n",
            "predicted: congress, use the power of the purse...!\n",
            "151/200 epochs\n",
            "loss: 7.027171611785889\n",
            "sample predictions:\n",
            "original : baroness remember, nbc celebrity 2 hours starting this sunday night at 9 p. m through end of season - great news for\n",
            "predicted: . remember, nbc. celebrity.. 2 hours. this sunday night at 9 p. m. through end of season - great news for...\n",
            "152/200 epochs\n",
            "loss: 6.805987358093262\n",
            "sample predictions:\n",
            "original : \" @olgin : @ real tropicalaldtrump do u ever get? \" yes, when i look at's happening to our country!\n",
            "predicted: . \" @.olgin :. @ real.aldtrump do u ever..? \" yes, when i look at.'s happening to our.!.\n",
            "153/200 epochs\n",
            "loss: 7.164884090423584\n",
            "sample predictions:\n",
            "original : @ dollibyron : @ realdontrump this is my favorite show geek! \"\n",
            "predicted: .. @ dollibyron : @ realdon.trump this. my favorite show..!. \"\n",
            "154/200 epochs\n",
            "loss: 6.888464450836182\n",
            "sample predictions:\n",
            "original : does anyoneobama did write85 the 1991 publisher?\n",
            "predicted: . does anyone....obama did..... the 1991 publisher.?\n",
            "155/200 epochs\n",
            "loss: 6.74047327041626\n",
            "sample predictions:\n",
            "original : \" @gargu : @ uniquetrump so right as usual you should but a big pay cut. are what we need. you!\n",
            "predicted: \" @..gargu. : @...trump.. so right as usual. you should. but.. a big pay cut.. are what we need... you!\n",
            "156/200 epochs\n",
            "loss: 6.633175373077393\n",
            "sample predictions:\n",
            "original : entrepreneurs : ask yourself : what can i exist be to new ideas. be innovative!\n",
            "predicted: . : ask yourself : what can i..... exist. be. to new ideas. be innovative!\n",
            "157/200 epochs\n",
            "loss: 6.68273401260376\n",
            "sample predictions:\n",
            "original : besides award winning golf course @ trumpfla features exquisite estates on top the paloss peninsula http : / / t. co / xtxcqqfu\n",
            "predicted: . besides. award winning golf course @ trump.fla features exquisite estates on. the palos.s peninsula http : / / t. co / xtxcqqfu..\n",
            "158/200 epochs\n",
            "loss: 6.767731666564941\n",
            "sample predictions:\n",
            "original : with mcaffe, virginia, at trump winery in charlotte explorers, - - on east coast @va : / / t. co / onchwxl\n",
            "predicted: with. mca.ffe,.. virginia, at. trump winery in charlotte.,.. -. on east coast. @.va. : / / t. co / onch.wx.l\n",
            "159/200 epochs\n",
            "loss: 7.090550422668457\n",
            "sample predictions:\n",
            "original : 11 elisac006 : @mia @ realdontrum i.ne looks like a fool!! \"\n",
            "predicted: .. elisac006 : @.mia @ realdon.trum. i...ne looks like a fool!! \".\n",
            "160/200 epochs\n",
            "loss: 6.488933086395264\n",
            "sample predictions:\n",
            "original : \" @ sarahlynellis : the donald three people this past episode realaldp that s why he's the best! celebrityapprentice \"\n",
            "predicted: \" @ sarahlynellis : the donald. three people this past episode. real.ald.p that. s why he's the best!. celebrityapprentice \"\n",
            "161/200 epochs\n",
            "loss: 6.848112106323242\n",
            "sample predictions:\n",
            "original : here ’ s something about donald trump, he a rated show on tv and everything he says becomes a. ” - @oes all true!\n",
            "predicted: .. here ’ s something about donald trump, he... a. rated. on. and everything he says becomes a.. ” - @.oes. all true!.\n",
            "162/200 epochs\n",
            "loss: 6.822628021240234\n",
            "sample predictions:\n",
            "original : ##nana thanks, good question / good point.\n",
            "predicted: ..nana thanks, good question / good point.\n",
            "163/200 epochs\n",
            "loss: 6.303254127502441\n",
            "sample predictions:\n",
            "original : billwy. thanks bill!\n",
            "predicted: . billw..y. thanks bill!\n",
            "164/200 epochs\n",
            "loss: 6.624119758605957\n",
            "sample predictions:\n",
            "original : phoenix convention center did want to have thousands of people outside the, so they let them in a great day!\n",
            "predicted: phoenix convention center. did. want to have thousands of people. outside. the., so they let them in. a great day!\n",
            "165/200 epochs\n",
            "loss: 6.789770603179932\n",
            "sample predictions:\n",
            "original : my @ foxandiends interview re : firing @ bretmichaels the premiere of - starnbc & amp ; http : / / t strangers co yoeojcj4rn\n",
            "predicted: . my @ foxand.iends interview re : firing @ bretmichaels. the premiere of. - star..nbc & amp ;. http. / / t. co. yoeojcj4rn\n",
            "166/200 epochs\n",
            "loss: 6.627209186553955\n",
            "sample predictions:\n",
            "original : president reagan put it best : \" s should to eliminate, as far as possible the need its own. \"\n",
            "predicted: president reagan put it best : \".. s. should. to eliminate, as far as possible. the need. its own.. \".\n",
            "167/200 epochs\n",
            "loss: 6.789969444274902\n",
            "sample predictions:\n",
            "original : so people are seeing benefits of the cut bill everyone is talking, really nice to see\n",
            "predicted: so. people are seeing. benefits of the. cut bill. everyone is talking, really nice to see..\n",
            "168/200 epochs\n",
            "loss: 6.646688938140869\n",
            "sample predictions:\n",
            "original : \" @ megrunder :. @ real brunoald frescop is any you aren t an expert? \", not many\n",
            "predicted: \" @ megrunder :. @ real.ald.p is. any. you aren. t an expert.? \"., not many.\n",
            "169/200 epochs\n",
            "loss: 6.648463249206543\n",
            "sample predictions:\n",
            "original : \" obamacare puts poor people a form of government run, - payer health insurance that many don'take \" - @ avik\n",
            "predicted: . \" obamacare puts poor people. a form of government run,. - payer health insurance that many. don '. take \" - @ avik.\n",
            "170/200 epochs\n",
            "loss: 6.717147350311279\n",
            "sample predictions:\n",
            "original : perhaps barack biggest shortcoming as president he failed to unite the country\n",
            "predicted: perhaps. barack.... biggest shortcoming as president. he failed to unite the country..\n",
            "171/200 epochs\n",
            "loss: 7.099410057067871\n",
            "sample predictions:\n",
            "original : @ angie _ ncislover have a happy one!\n",
            "predicted: @. _ ncislover have a happy one!.\n",
            "172/200 epochs\n",
            "loss: 6.67664098739624\n",
            "sample predictions:\n",
            "original : the 1945 are to a big impact on the election @ mittromney has proved - in florida - he delivers under.\n",
            "predicted: the. are. to. a big impact on the election. @ mittromney has proved. - in florida. - he delivers under...\n",
            "173/200 epochs\n",
            "loss: 6.782412052154541\n",
            "sample predictions:\n",
            "original : @ miranda _ dip : @ realdonaldtrump is than just a he a brilliant entrepreneur. \" thank you.\n",
            "predicted: . @ miranda _. dip. : @ realdonaldtrump is.. than just a.. he. a brilliant entrepreneur... \" thank you.\n",
            "174/200 epochs\n",
            "loss: 6.354706287384033\n",
            "sample predictions:\n",
            "original : \" peaceiswe [unused794]ness trump 2016 is the only to the decline of the west. only one man in america deal with putin # trump2016\n",
            "predicted: \". peaceiswe.ness. trump 2016 is the only. to. the decline of the west. only one man in america. deal with putin # trump2016\n",
            "175/200 epochs\n",
            "loss: 6.668145179748535\n",
            "sample predictions:\n",
            "original : “ ‘ the donald ’ a muske paulo / / t. co /m0z1lz1 via @ fitsws\n",
            "predicted: “ ‘ the donald ’. a muske.... / / t. co /.m.0z1lz1 via @ fits.ws\n",
            "176/200 epochs\n",
            "loss: 6.412979602813721\n",
            "sample predictions:\n",
            "original : \" @saxx : @ realdon marstrum http : / co zf93k6on \"\n",
            "predicted: \" @.saxx : @ realdon.trum. http : /... co. zf93k..6on \"\n",
            "177/200 epochs\n",
            "loss: 6.878493309020996\n",
            "sample predictions:\n",
            "original : the @ sent accessedcruz endorsement was a surprise. i [unused918] support! we will a tremendous victory on november.\n",
            "predicted: . the @ sent.cruz endorsement was a. surprise. i... support! we will. a tremendous victory on november..\n",
            "178/200 epochs\n",
            "loss: 6.4749956130981445\n",
            "sample predictions:\n",
            "original : winner of the 5 star diamond award,golfdc s over 600 acres on the river http : / t. / s8ivxvp\n",
            "predicted: winner of the 5 star diamond award,..golfdc. s... over 600 acres on the. river http :. / t.. / s8ivx..vp\n",
            "179/200 epochs\n",
            "loss: 6.639865875244141\n",
            "sample predictions:\n",
            "original : \" @ dardonyc fitness : @ realdonaldtrump donaldj boppj wood shots to get on that green stunning hole and best course in the world!\n",
            "predicted: \" @ dardonyc. : @ realdonaldtrump. donaldj.pj... wood shots to get on that green. stunning hole and best course in the world!\n",
            "180/200 epochs\n",
            "loss: 6.757368564605713\n",
            "sample predictions:\n",
            "original : chris ruddy is always on 出 motivation \" trump opens'greatest golf course the world'\" : / t. co / imy5ws martyrsr via @ newsmax _ media\n",
            "predicted: chris ruddy is always on.. \" trump opens. greatest golf.. the world'\". : /. t. co / imy5ws.r via @ newsmax _ media\n",
            "181/200 epochs\n",
            "loss: 6.553117752075195\n",
            "sample predictions:\n",
            "original : skirmish it ’ s very sad that isn ’ t sending anyone to margaret thatcher ’ funeral. she was a. s. supporter\n",
            "predicted: . it. s very sad that.. isn ’ t sending anyone to margaret thatcher ’. funeral. she was a... s. supporter.\n",
            "182/200 epochs\n",
            "loss: 6.541869163513184\n",
            "sample predictions:\n",
            "original : \" @ gretawire : presoba is not busy talking congress about syria.. he is golf... go figure \"\n",
            "predicted: \" @ gretawire : presoba. is not busy talking. congress about syria.. he is. golf... go figure \"\n",
            "183/200 epochs\n",
            "loss: 6.518388748168945\n",
            "sample predictions:\n",
            "original : # trumpvine weiner is a joke.. : t. co / dr34wsey\n",
            "predicted: # trump. weiner is a joke..... :.. t. co /..34wsey.\n",
            "184/200 epochs\n",
            "loss: 6.563344955444336\n",
            "sample predictions:\n",
            "original : great! https : / t. co / onxldv\n",
            "predicted: .. great.! https : /. t. co / on.x.ldv..\n",
            "185/200 epochs\n",
            "loss: 6.837368011474609\n",
            "sample predictions:\n",
            "original : \" @ chris julien8 : @ exceptiondonaldtrump excellent taste in trump wine. i trump red amp ; white! \"\n",
            "predicted: \" @ chris....8 : @.donaldtrump excellent taste in trump wine. i. trump red. amp ; white! \"...\n",
            "186/200 epochs\n",
            "loss: 6.945213317871094\n",
            "sample predictions:\n",
            "original : read @ ibdinvestors editorial : “ child alien obama fault, but gop won't pounce ” http : / / t. co jazz8qzyi\n",
            "predicted: . read @ ibdin.tors editorial : “ child alien. obama.. fault, but gop won't po. ” http : / / t. co. jazz.8qzyi\n",
            "187/200 epochs\n",
            "loss: 6.564934730529785\n",
            "sample predictions:\n",
            "original : ' a real hard time the academy ( so far ). last song was terrible kim should sue her plastic surgeon! #olars\n",
            "predicted: .. '.. a real hard time. the academy. ( so far ).. last song was terrible. kim should sue her plastic surgeon! #.s\n",
            "188/200 epochs\n",
            "loss: 6.445472240447998\n",
            "sample predictions:\n",
            "original : “ way do is to love what you do. if you haven ’ t found it yet, looking. don ’ t. ” – steve jobs\n",
            "predicted: “.. way. do.. is to love what you do. if you haven ’ t found it yet,. looking. don ’ t.. ” – steve jobs.\n",
            "189/200 epochs\n",
            "loss: 7.304365158081055\n",
            "sample predictions:\n",
            "original : canada lacey s pm in china last week broker a deal to emma the oil @obama rejected in keystone. http : / / t. / pm2rb3 unbelievable!\n",
            "predicted: .. s pm. in china last week broker. a deal to. the oil @.obama rejected in keystone. http : / / t.. / pm.2rb. unbelievable!.\n",
            "190/200 epochs\n",
            "loss: 6.723057270050049\n",
            "sample predictions:\n",
            "original : succession you grand michigan! time to end political correctness evacuate amp ; secure our homeland / /. / cyxjg3 https : / t. co pprriltfga\n",
            "predicted: .. you grand.. michigan! time to end political correct.. amp ; secure our homeland... / /... / cy....jg3 https :. / t. co. pprriltfga\n",
            "191/200 epochs\n",
            "loss: 6.926830768585205\n",
            "sample predictions:\n",
            "original : now a small country like sudan tells obama he can't send any more http / /. co / kmstnubh we are stock.\n",
            "predicted: now a. country like. tells obama. can't send any more. http. / /.. co / kmstnubh we are....\n",
            "192/200 epochs\n",
            "loss: 6.7779436111450195\n",
            "sample predictions:\n",
            "original : \" @ juliemroberts3 : @rivers @ joan rivers @nbc @ realdonaldtrump she was melissa! albert!ish memories! \"\n",
            "predicted: \" @ juliemroberts3. @.rivers @ joan. rivers @.nbc @ realdonaldtrump she was. melissa!..!.ish. memories! \".\n",
            "193/200 epochs\n",
            "loss: 6.472693920135498\n",
            "sample predictions:\n",
            "original : \" @ nerae : i'm not even american and see realdonp win! a person like him is going to set a new standard for leaders!\n",
            "predicted: \" @.rae. : i'm not even american and... see. realdon..p win! a person like him is.. set a new standard for. leaders!.\n",
            "194/200 epochs\n",
            "loss: 6.758813381195068\n",
            "sample predictions:\n",
            "original : i will let the of the remembrance project makericasafeagain : / / t. co / emft6rp https / / t. co / fhp44wixx\n",
            "predicted: i will. let the. of the..... make.ricasafeagain. : / / t. co / em.ft.6rp https. / / t. co / fhp.44wixx.\n",
            "195/200 epochs\n",
            "loss: 6.626182556152344\n",
            "sample predictions:\n",
            "original : @gop / / t co / scvacj customers\n",
            "predicted: .. @..p... / / t. co / scvac.j..\n",
            "196/200 epochs\n",
            "loss: 6.914787292480469\n",
            "sample predictions:\n",
            "original : # lasts sawyerp8 xu22 for exclusive realaldtrump updates we make america great mistakes!\n",
            "predicted: #..p8.22 for exclusive. real.aldtrump updates. we. make america..!\n",
            "197/200 epochs\n",
            "loss: 6.538134574890137\n",
            "sample predictions:\n",
            "original : half of americans don't pay income despite crippling govt debt... ballard / t symphonies co guj0kt\n",
            "predicted: half of americans don't pay income. despite crippling govt debt..... /. t. co. g.uj0kt\n",
            "198/200 epochs\n",
            "loss: 6.578589916229248\n",
            "sample predictions:\n",
            "original : \" @ dr _ : reuters 5 - day rolling : 34 %, carson 19. 6 % rub, cruz. 7 %.. thank you - a great honor\n",
            "predicted: . \" @ dr. _. : reuters 5 - day rolling. :. 34 %, carson 19. 6 %. rub...... cruz.. 7 %.... thank you - a great honor.\n",
            "199/200 epochs\n",
            "loss: 6.748798847198486\n",
            "sample predictions:\n",
            "original : getting ready land. looking much forward to meeting with our great madeleine / veterans at pearl!\n",
            "predicted: getting ready. land... looking. much forward to meeting with our great. / veterans at pearl.!\n",
            "200/200 epochs\n",
            "loss: 6.920245170593262\n",
            "sample predictions:\n",
            "original : \" @ savehicno1 @aldtrum @ mooovin _ on i will gladly be your campaign manager donald i clifton to be acidic last election \"\n",
            "predicted: \" @ savehicno1. @..aldtrum. @ mooovin _ on i will gladly be your campaign manager donald i.. to be. last. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24J64_s18fh6",
        "colab_type": "code",
        "outputId": "99e599e5-d0b2-415a-f803-02e0f8c4820c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Bert as Text Generator: https://arxiv.org/pdf/1902.04094.pdf\n",
        "def generate_tweet(model, length):\n",
        "  tweet = np.random.randint(len(tokenizer), size=(length))\n",
        "  order = np.random.permutation(range(length))\n",
        "  for i in order:\n",
        "    tweet[i] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "    inputs = torch.as_tensor([tweet], dtype=torch.int64)\n",
        "    labels = inputs.clone()\n",
        "    labels = torch.full((1, length), -1, dtype=torch.int64)\n",
        "    labels[0][i] = inputs[0][i]\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      outputs = model(inputs)\n",
        "    predictions = predict(inputs, outputs[0], labels)\n",
        "    tweet[i] = predictions[0][i]\n",
        "    print(tokenizer.decode(tweet))\n",
        "  return tweet\n",
        "\n",
        "# Generate a tweet\n",
        "tweet = generate_tweet(model, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weekendcar. trombonebedo meridiancre surprise parishes sandals\n",
            "weekendcar. trombone. meridiancre surprise parishes sandals\n",
            "weekendcar. trombone. meridian. surprise parishes sandals\n",
            ".car. trombone. meridian. surprise parishes sandals\n",
            ".car. trombone. meridian.. parishes sandals\n",
            ".car. trombone. meridian... sandals\n",
            "... trombone. meridian... sandals\n",
            "... trombone..... sandals\n",
            "... trombone......\n",
            "..........\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}